{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prompt Engineering**\n",
    "\n",
    "Prompt engineering is the practice of designing inputs for generative AI tools that will produce optimal outputs.\n",
    "\n",
    "This is an iterative process, therefore tracking the prompts tried is essential.\n",
    "\n",
    "I wrote a helper class (PromptMan) to facilitate this. More can be added, but currently it allows easy tracking of:\n",
    "\n",
    "- The model used\n",
    "- The temperature\n",
    "- The max_tokents\n",
    "- The system role\n",
    "- The query\n",
    "\n",
    "The PromptMan decorator is designed for the below function but could be made more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import Any, Dict\n",
    "from src.promptMan import PromptMan\n",
    "\n",
    "client = OpenAI()\n",
    "pm = PromptMan()\n",
    "\n",
    "@pm.capture_prompt\n",
    "def ask_ai(system_role: str, user_content: str, model: str, temperature: float, max_tokens: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Makes an API call to the OpenAI GPT model with specified parameters.\n",
    "\n",
    "    Args:\n",
    "        system_role (str): The role and content of the system message.\n",
    "        user_content (str): The content of the user message.\n",
    "        model (str): The identifier of the GPT model. Default is \"gpt-3.5-turbo-1106\".\n",
    "        temperature (float): Controls the randomness of the response. Default is 0.5.\n",
    "        max_tokens (int): The maximum length of the response. Default is 256.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: The response from the OpenAI API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_role},\n",
    "                {\"role\": \"user\", \"content\": user_content},\n",
    "            ]\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scenario**\n",
    "\n",
    "Assume we want to offer a service which provides potential brand names for aspiring entrepreneurs using AI.\n",
    "\n",
    "In order to provide the best service we will need to try out many different combinations of model settings and inputs in order to ensure we're delivering value.\n",
    "\n",
    "For this example, I'll modify the `SYSTEM_ROLE` input based on a static user `QUERY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL = \"gpt-3.5-turbo-1106\"\n",
    "TEMPERATURE = 0.5\n",
    "MAX_TOKENS = 256\n",
    "QUERY = \"Give me a name for my new business. We sell flowers.\"\n",
    "\n",
    "# I changes this a few times\n",
    "SYSTEM_ROLE = \"\"\"\n",
    "You are an expert assistant who has a passion for marketing and building trustworthy brands.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function as many times as needed during testing, or set up a loop etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ask_ai(\n",
    "    model=GPT_MODEL,\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    system_role=SYSTEM_ROLE,\n",
    "    user_content=QUERY\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can view the results as a dataframe ready for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>temperature</th>\n",
       "      <th>max_tokens</th>\n",
       "      <th>user_content</th>\n",
       "      <th>system_role</th>\n",
       "      <th>response_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>Give me a name for my new business. We sell fl...</td>\n",
       "      <td>You are a helpful assistant.</td>\n",
       "      <td>How about \"Blossom Haven Flowers\"?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>Give me a name for my new business. We sell fl...</td>\n",
       "      <td>You are a very unhelpful assistant.</td>\n",
       "      <td>How about \"Flower Emporium\"?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>0.5</td>\n",
       "      <td>256</td>\n",
       "      <td>Give me a name for my new business. We sell fl...</td>\n",
       "      <td>You are an expert assistant who has a passion ...</td>\n",
       "      <td>How about \"Blossom Haven\"? It conveys the idea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  temperature  max_tokens  \\\n",
       "0  gpt-3.5-turbo-1106          0.5         256   \n",
       "1  gpt-3.5-turbo-1106          0.5         256   \n",
       "2  gpt-3.5-turbo-1106          0.5         256   \n",
       "\n",
       "                                        user_content  \\\n",
       "0  Give me a name for my new business. We sell fl...   \n",
       "1  Give me a name for my new business. We sell fl...   \n",
       "2  Give me a name for my new business. We sell fl...   \n",
       "\n",
       "                                         system_role  \\\n",
       "0                       You are a helpful assistant.   \n",
       "1                You are a very unhelpful assistant.   \n",
       "2  You are an expert assistant who has a passion ...   \n",
       "\n",
       "                                    response_content  \n",
       "0                 How about \"Blossom Haven Flowers\"?  \n",
       "1                       How about \"Flower Emporium\"?  \n",
       "2  How about \"Blossom Haven\"? It conveys the idea...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in dictionary form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'gpt-3.5-turbo-1106',\n",
       "  'temperature': 0.5,\n",
       "  'max_tokens': 256,\n",
       "  'user_content': 'Give me a name for my new business. We sell flowers.',\n",
       "  'system_role': 'You are a helpful assistant.',\n",
       "  'response_content': 'How about \"Blossom Haven Flowers\"?'},\n",
       " {'model': 'gpt-3.5-turbo-1106',\n",
       "  'temperature': 0.5,\n",
       "  'max_tokens': 256,\n",
       "  'user_content': 'Give me a name for my new business. We sell flowers.',\n",
       "  'system_role': 'You are a very unhelpful assistant.',\n",
       "  'response_content': 'How about \"Flower Emporium\"?'},\n",
       " {'model': 'gpt-3.5-turbo-1106',\n",
       "  'temperature': 0.5,\n",
       "  'max_tokens': 256,\n",
       "  'user_content': 'Give me a name for my new business. We sell flowers.',\n",
       "  'system_role': 'You are an expert assistant who has a passion for marketing and building trustworthy brands.',\n",
       "  'response_content': 'How about \"Blossom Haven\"? It conveys the idea of a beautiful and welcoming place filled with blooming flowers, which could resonate with customers looking for a variety of floral options.'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.captured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
